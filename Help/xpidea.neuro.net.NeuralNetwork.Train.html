<html dir="LTR"><head><META http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="vs_targetSchema" content="http://schemas.microsoft.com/intellisense/ie5"><title>NeuralNetwork.Train Method</title><xml></xml><link rel="stylesheet" type="text/css" href="MSDN.css"></head><body id="bodyID" class="dtBODY"><div id="nsbanner"><div id="bannerrow1"><table class="bannerparthead" cellspacing="0"><tr id="hdr"><td class="runninghead">XP Idea Neural Networks Library</td><td class="product"></td></tr></table></div><div id="TitleRow"><h1 class="dtH1">NeuralNetwork.Train Method </h1></div></div><div id="nstext"><p> Performs network training. Here you write the code to train your network. </p><div class="syntax">public virtual <a href="ms-help://MS.NETFrameworkSDKv1.1/cpref/html/frlrfSystemVoidClassTopic.htm">void</a> Train(<br>   <a href="xpidea.neuro.net.patterns.PatternsCollection.html">PatternsCollection</a> <i>patterns</i><br>);</div><h4 class="dtH4">Parameters</h4><dl><dt><i>patterns</i></dt><dd>Set of the patterns that will be exposed to a network during the training.</dd></dl><h4 class="dtH4">Remarks</h4><p>There are several major paradigms, or approaches, to neural network learning. These include <i>supervised, unsupervised</i>, and <i>reinforcement</i> learning. How the training data is processed is a major aspect of these learning paradigms.</p><p><i>Supervised</i> learning is the most common form of learning and is sometimes called programming by example. The neural network is trained by showing it examples of the problem state or attributes along with the desired output or action. The neural network makes a prediction based on the inputs and if the output differs from the desired out put, then the network is adjusted or adapted to produce the correct output. This process is repeated over and over until the agent learns to make accurate classifications or predictions. Historical data from databases, sensor logs, or trace logs is often used as the training or example data. </p><p><i>Unsupervised</i> learning is used when the neural network needs to recognize similarities between inputs or to identify features in the input data. The data is presented to the network, and it adapts so that it partitions the data into groups. The clustering or segmenting process continues until the neural network places the same data into the same group on successive passes over the data. An unsupervised learning algorithm performs a type of feature detection where important common attributes in the data are extracted. The Kohonen map will be a good example of the network using unsupervised learning.</p><p><i>Reinforcement</i> learning is a type of supervised learning used when explicit input/ output pairs of training data are not available. It can be used in cases where there is a sequence of inputs arid the desired output is only known after the specific sequence occurs. This process of identifying the relationship between a series of input values and a later output value is called temporal credit assignment. Because we provide less specific error information, reinforcement learning usually takes longer than supervised learning and is less efficient. However, in many situations, having exact prior information about the desired outcome is not possible. In many ways, reinforcement learning is the most realistic form of learning. </p><h4 class="dtH4">See Also</h4><p><a href="xpidea.neuro.net.NeuralNetwork.html">NeuralNetwork Class</a> | <a href="xpidea.neuro.net.html">xpidea.neuro.net Namespace</a></p><object type="application/x-oleobject" classid="clsid:1e2a7bd0-dab9-11d0-b93a-00c04fc99f9e" viewastext="true" style="display: none;"><param name="Keyword" value="Train method"><param name="Keyword" value="Train method, NeuralNetwork class"><param name="Keyword" value="NeuralNetwork.Train method"></object><hr><div id="footer"><p><a href="mailto:info@xpidea.com?subject=XP Idea Neural Networks Library Documentation Feedback: NeuralNetwork.Train%C2%A0Method%C2%A0">Send comments on this topic.</a></p><p><a>Copyright (c) 2001-2004 Alex Cherkasov</a></p><p></p></div></div></body></html>